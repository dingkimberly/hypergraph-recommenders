{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import sparse\n",
    "\n",
    "# Reference: https://beckernick.github.io/music_recommender/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in tsv files. \n",
    "user_data = pd.read_table('usersha1-artmbid-artname-plays.tsv',\n",
    "                          header = None, \n",
    "                          names = ['users', 'musicbrainz-artist-id', 'artist-name', 'plays'],\n",
    "                          usecols = ['users', 'artist-name', 'plays'])\n",
    "user_profiles = pd.read_table('usersha1-profile.tsv',\n",
    "                          header = None,\n",
    "                          names = ['users', 'gender', 'age', 'country', 'signup'],\n",
    "                          usecols = ['users', 'country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove artists with no plays. \n",
    "if user_data['artist-name'].isnull().sum() > 0:\n",
    "    user_data = user_data.dropna(axis = 0, subset = ['artist-name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column with sum of total artist plays.\n",
    "artist_plays = (user_data.\n",
    "     groupby(by = ['artist-name'])['plays'].\n",
    "     sum().\n",
    "     reset_index().\n",
    "     rename(columns = {'plays': 'total_artist_plays'})\n",
    "     [['artist-name', 'total_artist_plays']]\n",
    "    )\n",
    "\n",
    "user_data_with_artist_plays = user_data.merge(artist_plays, left_on = 'artist-name', right_on = 'artist-name', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove artists with less than popularity_threshold plays. \n",
    "popularity_threshold = 1000000\n",
    "\n",
    "user_data_popular_artists = user_data_with_artist_plays.query('total_artist_plays >= @popularity_threshold')\n",
    "combined = user_data_popular_artists.merge(user_profiles, left_on = 'users', right_on = 'users', how = 'left')\n",
    "\n",
    "usa_data = combined.query('country == \\'United States\\'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column with sum of total user plays. \n",
    "user_plays = (usa_data.\n",
    "     groupby(by = ['users'])['plays'].\n",
    "     sum().\n",
    "     reset_index().\n",
    "     rename(columns = {'plays': 'total_user_plays'})\n",
    "     [['users', 'total_user_plays']]\n",
    "    )\n",
    "\n",
    "plays_data = usa_data.merge(user_plays, left_on = 'users', right_on = 'users', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove users with less than plays_threshold plays. \n",
    "plays_threshold = 1000\n",
    "\n",
    "final_data = plays_data.query('total_user_plays >= @plays_threshold')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating hypergraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# E: number of users\n",
    "# V: number of artists\n",
    "# erase_prob: chance user rating is erased (for UDOA)\n",
    "def make_hypergraph(E, V, erase_prob, random_seed):\n",
    "    np.random.seed(random_seed)\n",
    "    \n",
    "    max_users = E\n",
    "    max_artists = V\n",
    "     \n",
    "    W = np.zeros((V, E)) # hyperedge-weight matrix, |V|x |E|, each row corresponds to a movie. \n",
    "    R = np.zeros((E, V)) # edge-dependent vertex-weight matrix, |E| x |V|, each row corresponds to a user.\n",
    "    true_R = np.zeros((E, V)) # same but without erasing.\n",
    "\n",
    "    num_pairs = 0\n",
    "    \n",
    "    curr_avail_user_index = 0\n",
    "    curr_avail_artist_index = 0\n",
    "    user_dict = {} \n",
    "    artist_dict = {}\n",
    "    \n",
    "    for _, row in final_data.iterrows():\n",
    "        user = row['users']\n",
    "        artist = row['artist-name']\n",
    "        plays = int(row['plays'])\n",
    "\n",
    "        user_index = user_dict.get(user)\n",
    "\n",
    "        if user_index == None:\n",
    "            if curr_avail_user_index < max_users:\n",
    "                user_dict[user] = curr_avail_user_index\n",
    "                user_index = curr_avail_user_index\n",
    "                curr_avail_user_index += 1\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        artist_index = artist_dict.get(artist)\n",
    "\n",
    "        if artist_index == None:\n",
    "            if curr_avail_artist_index < max_artists:\n",
    "                artist_dict[artist] = curr_avail_artist_index\n",
    "                artist_index = curr_avail_artist_index\n",
    "                curr_avail_artist_index += 1\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        true_R[user_index][artist_index] = plays\n",
    "\n",
    "        err = np.random.rand(1)\n",
    "        if err > erase_prob:\n",
    "            W[artist_index][user_index] = 1\n",
    "            R[user_index][artist_index] = plays\n",
    "\n",
    "            num_pairs += 1\n",
    "            \n",
    "    return W, R, true_R, num_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_similarities(E, V, R):\n",
    "    power_similarities = np.ones((E, E))\n",
    "    dot_similarities = np.ones((E, E))\n",
    "\n",
    "    for i in range(E):\n",
    "        for j in range(i+1, E):\n",
    "\n",
    "            dot_product = np.dot(R[i], R[j])\n",
    "\n",
    "            if dot_product > 1:\n",
    "                dot_similarities[i][j] = dot_product\n",
    "                dot_similarities[j][i] = dot_product  \n",
    "\n",
    "            for song in range(V):\n",
    "                if R[i][song] != 0 and R[j][song] != 0:\n",
    "\n",
    "                    power_similarities[i][j] *= 2\n",
    "                    power_similarities[j][i] *= 2\n",
    "                    \n",
    "    return power_similarities, dot_similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want the nonzero rows of W and R to sum to 1 \n",
    "def row_normalize(X):\n",
    "    Y = np.matrix.copy(X)\n",
    "    for i in range(len(Y)):\n",
    "        row = Y[i]\n",
    "        row_sum = np.sum(row)\n",
    "        if row_sum != 0:\n",
    "            Y[i] = Y[i]/row_sum   \n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_P(W, R):\n",
    "    Rs = sparse.csr_matrix(row_normalize(R))\n",
    "    Ws = sparse.csr_matrix(row_normalize(W))\n",
    "    P = np.transpose(Ws.dot(Rs))\n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A weight matrix customized for a particular user.\n",
    "def get_Wi(W, user_index, similarities):\n",
    "    Wi = np.copy(W)\n",
    "    for other_user_index in range(len(similarities[user_index])):\n",
    "        if other_user_index == user_index:\n",
    "            continue\n",
    "        similarity = similarities[user_index][other_user_index]\n",
    "        Wi[:,other_user_index] *= similarity\n",
    "        \n",
    "    return Wi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_P_hg(Wi, R):\n",
    "    Rs = sparse.csr_matrix(row_normalize(R))\n",
    "    Wis = sparse.csr_matrix(row_normalize(Wi))\n",
    "    Pi = np.transpose(Wis.dot(Rs))\n",
    "    return Pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_P_g(Wi, E, V, R, num_pairs):\n",
    "    \n",
    "    WiG = np.zeros((V+E, num_pairs)) \n",
    "    RG = np.zeros((num_pairs, V+E)) \n",
    "\n",
    "    curr_edge_index = 0 \n",
    "\n",
    "    for i in range(V):\n",
    "        for j in range(E):\n",
    "            if R[j][i] != 0:\n",
    "                # index of movie i in graph = i\n",
    "                # index of user j in graph = V+j\n",
    "\n",
    "                RG[curr_edge_index][V+j] = 1\n",
    "                RG[curr_edge_index][i] = 1\n",
    "\n",
    "                WiG[V+j][curr_edge_index] = Wi[i][j] * R[j][i]\n",
    "                WiG[i][curr_edge_index] = WiG[V+j][curr_edge_index]\n",
    "\n",
    "                curr_edge_index += 1\n",
    "                \n",
    "    WiGs = sparse.csr_matrix(row_normalize(WiG))\n",
    "    RGs = sparse.csr_matrix(row_normalize(RG))\n",
    "    PiG = np.transpose(WiGs.dot(RGs))\n",
    "    \n",
    "    return PiG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given probability transition matrix P\n",
    "# where P_{v,w} = Prob(w -> v)\n",
    "# find pagerank scores with restart probability r\n",
    "def compute_pr(P, r, n, home, eps=1e-8):\n",
    "    \n",
    "    x = np.ones(n) / n*1.0\n",
    "\n",
    "    flag = True\n",
    "    t=0\n",
    "        \n",
    "    while flag:\n",
    "        x_new = (1-r)*P*x\n",
    "\n",
    "        x_new = x_new + home * r \n",
    "        \n",
    "        if np.linalg.norm(x_new - x,ord=1) < eps and t > 100:\n",
    "            flag = False\n",
    "        t=t+1\n",
    "        x = x_new\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ranking_hg(user_index, V, R, P, r=0.15):\n",
    "    \n",
    "    # personalize the algorithm by restarting at any of the movies a certain user originally watched\n",
    "    home_hg = np.zeros(V)\n",
    "\n",
    "    for j in range(V):\n",
    "        if R[user_index][j] != 0:\n",
    "            home_hg[j] = 1\n",
    "\n",
    "    if np.sum(home_hg) > 0:\n",
    "        home_hg = home_hg / np.sum(home_hg)\n",
    "\n",
    "    ranking_hg = compute_pr(P, r, V, home_hg).flatten()\n",
    "        \n",
    "    return ranking_hg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ranking_g(user_index, V, E, P, r=0.15):\n",
    "    \n",
    "    # restart at user's vertex\n",
    "    home_g = np.zeros(V+E)\n",
    "    home_g[V+user_index] = 1\n",
    "\n",
    "    curr_rankings_g = compute_pr(P, r, V+E, home_g).flatten()\n",
    "    ranking_g = curr_rankings_g[:V]\n",
    "        \n",
    "    return ranking_g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://www.aaai.org/Papers/IJCAI/2007/IJCAI07-444.pdf\n",
    "def calc_avg_doa(num_movies, given_rating, true_rating, ranking):\n",
    "    \n",
    "    total_pairs = 0\n",
    "    correct_pairs = 0\n",
    "    \n",
    "    # All pairs of movies. \n",
    "    for i in range(num_movies):\n",
    "        for j in range(i+1, num_movies):\n",
    "            if true_rating[i] < true_rating[j]:\n",
    "                total_pairs += 1\n",
    "                if ranking[i] < ranking[j]:\n",
    "                    correct_pairs += 1\n",
    "            elif true_rating[i] > true_rating[j]:\n",
    "                total_pairs += 1\n",
    "                if ranking[i] > ranking[j]:\n",
    "                    correct_pairs += 1\n",
    "       \n",
    "    if total_pairs == 0:\n",
    "        return -1\n",
    "    return correct_pairs/total_pairs\n",
    "\n",
    "def calc_avg_udoa(num_movies, given_rating, true_rating, ranking):\n",
    "    \n",
    "    total_pairs = 0\n",
    "    correct_pairs = 0\n",
    "    \n",
    "    # All pairs of movies. \n",
    "    for i in range(num_movies):\n",
    "        for j in range(i+1, num_movies):\n",
    "            if given_rating[i] == 0 and true_rating[i] != 0 and given_rating[j] == 0 and true_rating[j] != 0:\n",
    "                if true_rating[i] < true_rating[j]:\n",
    "                    total_pairs += 1\n",
    "                    if ranking[i] < ranking[j]:\n",
    "                        correct_pairs += 1\n",
    "                elif true_rating[i] > true_rating[j]:\n",
    "                    total_pairs += 1\n",
    "                    if ranking[i] > ranking[j]:\n",
    "                        correct_pairs += 1\n",
    "       \n",
    "    if total_pairs == 0:\n",
    "        return -1\n",
    "    return correct_pairs/total_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to run things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_trials(E, V, W, R, true_R, num_pairs, similarities, is_hg):\n",
    "\n",
    "    udoa = 0\n",
    "    ucount = 0\n",
    "    \n",
    "    doa = 0\n",
    "    dcount = 0\n",
    "    \n",
    "    for i in range(E):\n",
    "        \n",
    "        Wi = get_Wi(W, i, similarities)\n",
    "        \n",
    "        if is_hg:\n",
    "            P = get_P_hg(Wi, R)\n",
    "            ranking = compute_ranking_hg(i, V, R, P)\n",
    "        else:\n",
    "            P = get_P_g(Wi, E, V, R, num_pairs)\n",
    "            ranking = compute_ranking_g(i, V, E, P)\n",
    "\n",
    "        curr_udoa = calc_avg_udoa(V, R[i], true_R[i], ranking)\n",
    "        curr_doa = calc_avg_doa(V, R[i], true_R[i], ranking)\n",
    "\n",
    "        if curr_udoa > -1:\n",
    "            udoa += curr_udoa\n",
    "            ucount += 1\n",
    "        if curr_doa > -1:\n",
    "            doa += curr_doa\n",
    "            dcount += 1\n",
    "    \n",
    "    if ucount != 0:\n",
    "        udoa = udoa/ucount\n",
    "    else:\n",
    "        udoa = -1\n",
    "        \n",
    "    if dcount != 0:\n",
    "        doa = doa/dcount\n",
    "    else:\n",
    "        doa = -1\n",
    "        \n",
    "    return doa, udoa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_dumb_trials_hg(E, V, R, true_R, P):\n",
    "\n",
    "    udoa = 0\n",
    "    ucount = 0\n",
    "    \n",
    "    doa = 0\n",
    "    dcount = 0\n",
    "    \n",
    "    for i in range(E):\n",
    "        \n",
    "        ranking = compute_ranking_hg(i, V, R, P)\n",
    "        curr_udoa = calc_avg_udoa(V, R[i], true_R[i], ranking) \n",
    "        curr_doa = calc_avg_doa(V, R[i], true_R[i], ranking)\n",
    "\n",
    "        if curr_udoa > -1:\n",
    "            udoa += curr_udoa\n",
    "            ucount += 1\n",
    "            \n",
    "        if curr_doa > -1:\n",
    "            doa += curr_doa\n",
    "            dcount += 1\n",
    "\n",
    "    if ucount != 0:\n",
    "        udoa = udoa/ucount\n",
    "    else:\n",
    "        udoa = -1\n",
    "        \n",
    "    if dcount != 0:\n",
    "        doa = doa/dcount\n",
    "    else:\n",
    "        doa = -1\n",
    "        \n",
    "    return doa, udoa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_dumb_trials_g(E, V, R, true_R, P):\n",
    "\n",
    "    udoa = 0\n",
    "    ucount = 0\n",
    "    \n",
    "    doa = 0\n",
    "    dcount = 0\n",
    "    \n",
    "    for i in range(E):\n",
    "        \n",
    "        ranking = compute_ranking_g(i, V, E, P)\n",
    "        curr_udoa = calc_avg_udoa(V, R[i], true_R[i], ranking) \n",
    "        curr_doa = calc_avg_doa(V, R[i], true_R[i], ranking)\n",
    "\n",
    "        if curr_udoa > -1:\n",
    "            udoa += curr_udoa\n",
    "            ucount += 1\n",
    "            \n",
    "        if curr_doa > -1:\n",
    "            doa += curr_doa\n",
    "            dcount += 1\n",
    "\n",
    "    if ucount != 0:\n",
    "        udoa = udoa/ucount\n",
    "    else:\n",
    "        udoa = -1\n",
    "        \n",
    "    if dcount != 0:\n",
    "        doa = doa/dcount\n",
    "    else:\n",
    "        doa = -1\n",
    "        \n",
    "    return doa, udoa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_everything(E, V, erase_prob, random_seed):\n",
    "    print(\"erase_prob=%.3f, random_seed=%d\" % (erase_prob, random_seed))\n",
    "\n",
    "    W, R, true_R, num_pairs = make_hypergraph(E, V, erase_prob, random_seed)\n",
    "    print(\"made hypergraph\")\n",
    "    \n",
    "    array = [0 for _ in range(7)] \n",
    "    power_sims, dot_sims = make_similarities(E, V, R)\n",
    "    P = get_P(W, R)\n",
    "    Pg = get_P_g(W, E, V, R, num_pairs)\n",
    "    \n",
    "    hgdumb, uhgdumb = run_dumb_trials_hg(E, V, R, true_R, P)\n",
    "    gdumb, ugdumb = run_dumb_trials_g(E, V, R, true_R, Pg)\n",
    "    print(\"finished trial 0\")\n",
    "    \n",
    "    hg1, uhg1 = run_trials(E, V, W, R, true_R, num_pairs, power_sims, True)\n",
    "    g1, ug1 = run_trials(E, V, W, R, true_R, num_pairs, power_sims, False)\n",
    "    print(\"finished trial 1\")\n",
    "    \n",
    "    hg2, uhg2 = run_trials(E, V, W, R, true_R, num_pairs, dot_sims, True)\n",
    "    g2, ug2 = run_trials(E, V, W, R, true_R, num_pairs, dot_sims, False)\n",
    "    print(\"finished trial 2\")\n",
    "    \n",
    "    #hg3, uhg3 = run_trials(E, V, W, R, true_R, num_pairs, log_dot_sims, True)\n",
    "    #g3, ug3 = run_trials(E, V, W, R, true_R, num_pairs, log_dot_sims, False)\n",
    "    #print(\"finished trial 3\")\n",
    "\n",
    "    return [hgdumb, uhgdumb, gdumb, ugdumb, hg1, uhg1, g1, ug1, hg2, uhg2, g2, ug2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_everything_n_times(E, V, erase_prob, n):\n",
    "    \n",
    "    avgs = [0 for _ in range(16)]\n",
    "    \n",
    "    for i in range(n):\n",
    "        udoas = do_everything(E, V, erase_prob, i)\n",
    "        avgs = np.add(avgs, udoas)\n",
    "        print()\n",
    "        \n",
    "    return np.divide(avgs, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actually running things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "erase_prob=0.150, random_seed=0\n",
      "made hypergraph\n",
      "finished trial 0\n",
      "finished trial 1\n",
      "finished trial 2\n",
      "finished trial 3\n",
      "\n",
      "erase_prob=0.150, random_seed=1\n",
      "made hypergraph\n",
      "finished trial 0\n",
      "finished trial 1\n",
      "finished trial 2\n",
      "finished trial 3\n",
      "\n",
      "erase_prob=0.150, random_seed=2\n",
      "made hypergraph\n",
      "finished trial 0\n",
      "finished trial 1\n",
      "finished trial 2\n",
      "finished trial 3\n",
      "\n",
      "erase_prob=0.150, random_seed=3\n",
      "made hypergraph\n",
      "finished trial 0\n",
      "finished trial 1\n",
      "finished trial 2\n",
      "finished trial 3\n",
      "\n",
      "erase_prob=0.150, random_seed=4\n",
      "made hypergraph\n",
      "finished trial 0\n",
      "finished trial 1\n",
      "finished trial 2\n",
      "finished trial 3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "array = do_everything_n_times(100, 500, 0.15, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dumb hypergraph doa: 0.9391555764739387\n",
      "dumb hypergraph udoa: 0.5278802584066591\n",
      "dumb graph doa: 0.9493473418399075\n",
      "dumb graph udoa: 0.5299835586804126\n",
      "\n",
      "power hypergraph doa: 0.9350590906964685\n",
      "power hypergraph udoa: 0.5293953240665242\n",
      "power graph doa: 0.9496647510289915\n",
      "power graph udoa: 0.5434046037834884\n",
      "\n",
      "dot hypergraph doa: 0.9367001736669389\n",
      "dot hypergraph udoa: 0.5205203618266889\n",
      "dot graph doa: 0.9477262268848042\n",
      "dot graph udoa: 0.5280138927767432\n"
     ]
    }
   ],
   "source": [
    "print(\"dumb hypergraph doa:\", array[0])\n",
    "print(\"dumb hypergraph udoa:\", array[1])\n",
    "print(\"dumb graph doa:\", array[2])\n",
    "print(\"dumb graph udoa:\", array[3])\n",
    "print()\n",
    "\n",
    "print(\"power hypergraph doa:\", array[4])\n",
    "print(\"power hypergraph udoa:\", array[5])\n",
    "print(\"power graph doa:\", array[6])\n",
    "print(\"power graph udoa:\", array[7])\n",
    "print()\n",
    "\n",
    "print(\"dot hypergraph doa:\", array[8])\n",
    "print(\"dot hypergraph udoa:\", array[9])\n",
    "print(\"dot graph doa:\", array[10])\n",
    "print(\"dot graph udoa:\", array[11])\n",
    "\n",
    "#print(\"log-dot hypergraph doa:\", array[12])\n",
    "#print(\"log-dot hypergraph udoa:\", array[13])\n",
    "#print(\"log-dot graph doa:\", array[14])\n",
    "#print(\"log-dot graph udoa:\", array[15])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
